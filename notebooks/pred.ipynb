{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pra prever a nota do **IMDB** (`IMDB_Rating`) tratei o problema como uma tarefa de **regress√£o**, j√° q a vari√°vel alvo √© continua (vai de 0 at√© 10).  \n",
    "\n",
    "As vari√°veis q usei foram:  \n",
    "- **Num√©ricas**: `Runtime` (convertido p/ minutos), `Meta_score`, `No_of_Votes`, `Gross` (ajustado p/ n√∫mero).  \n",
    "- **Categ√≥ricas**: `Genre`, `Certificate`, `Director` e os atores principais (`Star1`‚Äì`Star4`).  \n",
    "  Nessas apliquei `OneHot` ou contagem de freq p/ transformar em n√∫mero.  \n",
    "- **Transforma√ß√µes extras**:  \n",
    "  - Normalizei escalas num√©ricas ($MinMaxScaler$), pq atributos como $No\\_of\\_Votes$ e $Gross$ tem magnitudes mt diferentes.  \n",
    "  - No `Genre`, como pode ter + de um valor, fiz one-hot multir√≥tulo (cada g√™nero vira 0/1 separado).\n",
    "\n",
    "O modelo q testei foi o **Random Forest Regressor**.  \n",
    "- **Pr√≥s**: robusto a outliers, pega rela√ß√µes n√£o lineares, n precisa assumir distribui√ß√£o das vari√°veis.  \n",
    "- **Contras**: interpretabilidade baixa e custo comp. maior q modelos lineares.  \n",
    "\n",
    "Como m√©trica, escolhi o **RMSE** ($\\sqrt{MSE}$) pq d√° o erro m√©dio direto na escala do IMDB.  \n",
    "Al√©m disso tb usei o $R^2$ como complemento p/ ver a propor√ß√£o da vari√¢ncia explicada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = '..\\\\data\\\\processed\\\\final_df.csv'\n",
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "\n",
    "class FeatureCreator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, top_n_genres=15):\n",
    "        self.top_n_genres = top_n_genres\n",
    "        self.top_genres_ = []\n",
    "        self.max_year_ = 0\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        genres = X['Genre'].str.split(', ').explode()\n",
    "        self.top_genres_ = genres.value_counts().nlargest(self.top_n_genres).index.tolist()\n",
    "        if 'Released_Year' in X.columns:\n",
    "            self.max_year_ = X['Released_Year'].max()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        if 'Released_Year' in X_transformed.columns and self.max_year_ > 0:\n",
    "            X_transformed['Movie_Age'] = self.max_year_ - X_transformed['Released_Year']\n",
    "        for genre in self.top_genres_:\n",
    "            X_transformed[f'is_{genre}'] = X_transformed['Genre'].str.contains(genre, case=False, na=False).astype(int)\n",
    "        if 'Meta_score' in X_transformed.columns and 'No_of_Votes' in X_transformed.columns:\n",
    "            X_transformed['Metascore_x_Votes'] = X_transformed['Meta_score'] * X_transformed['No_of_Votes']\n",
    "        X_transformed = X_transformed.drop(columns=['Genre'], errors='ignore')\n",
    "        return X_transformed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engenharia de Features com `FeatureCreator`\n",
    "Aqui criamos um transformador customizado para enriquecer os dados de filmes antes de treinar o modelo.  \n",
    "O objetivo √© extrair vari√°veis mais informativas a partir das j√° existentes.\n",
    "\n",
    "- **Top G√™neros**: a coluna `Genre` pode conter m√∫ltiplos valores. Extra√≠mos os `top_n` g√™neros mais frequentes e criamos vari√°veis bin√°rias (`is_Drama`, `is_Action`, etc.) indicando se o filme pertence a eles. Isso ajuda o modelo a capturar rela√ß√µes entre g√™nero e nota do IMDB.  \n",
    "- **Idade do Filme**: calculamos `Movie_Age` como a diferen√ßa entre o ano mais recente do dataset e o ano de lan√ßamento. Filmes mais antigos tendem a acumular votos e avalia√ß√µes diferentes dos mais novos.  \n",
    "- **Intera√ß√£o entre notas e popularidade**: criamos a vari√°vel `Metascore_x_Votes`, que combina a avalia√ß√£o da cr√≠tica (`Meta_score`) com o n√∫mero de votos do p√∫blico (`No_of_Votes`). Essa intera√ß√£o pode ser um forte preditor da nota do IMDB, pois reflete a percep√ß√£o cr√≠tica e a representatividade da amostra de votos.  \n",
    "- Ao final, removemos a coluna original `Genre`, j√° que sua informa√ß√£o foi decomposta em vari√°veis mais √∫teis.\n",
    "\n",
    "Esse tipo de **engenharia de features direcionada** geralmente aumenta a capacidade preditiva de modelos baseados em √°rvores, como `GradientBoostingRegressor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gross_with_revenue(df):\n",
    "    df_copy = df.copy()\n",
    "    gross_mean = df_copy['Gross'].mean()\n",
    "    revenue_mean = df_copy['Revenue'].mean()\n",
    "    factor = revenue_mean / gross_mean if pd.notna(gross_mean) and pd.notna(revenue_mean) and gross_mean > 0 else 1.0\n",
    "    df_copy['Gross'] = df_copy['Gross'].fillna(df_copy['Revenue'] / factor)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fun√ß√£o de imputa√ß√£o de `Gross` com base em `Revenue`\n",
    "Muitos filmes n√£o t√™m valor de bilheteria (`Gross`) registrado, mas t√™m receita total (`Revenue`).  \n",
    "A estrat√©gia aqui √© preencher os valores ausentes de `Gross` estimando-os proporcionalmente a `Revenue`.\n",
    "\n",
    "- Calculamos um **fator de ajuste** como a raz√£o entre as m√©dias de $Revenue$ e $Gross.  \n",
    "- Quando $Gross$ √© nulo, substitu√≠mos por $\\frac{Revenue}{ fator}$.  \n",
    "- Essa t√©cncia reduz perda de informa√ß√£o sem simplesmente descartar linhas ou usar m√©dia bruta, mantendo coer√™ncia com a escala financeira dos filmes.  \n",
    "\n",
    "Essa abordagem evita **vazamnto de dados**, pq √© aplicada dentro de cada parti√ß√£o do treino/valida√ßao no pipeline, garantindo que estat√≠sticas de imputa√ß√£o sejam aprendidas apenas a partir dos dados disponiveis no conjunto de treino.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score R¬≤ (valida√ß√£o cruzada): 0.5264\n",
      "A treinar o modelo final com todos os dados...\n",
      "Treino conclu√≠do.\n",
      "Modelo salvo com sucesso no ficheiro: ../models/melhor_modelo.pkl\n"
     ]
    }
   ],
   "source": [
    "df_filled = fill_gross_with_revenue(df)\n",
    "\n",
    "gross_index = df_filled.columns.get_loc('Gross')\n",
    "cols_to_drop_after_gross = df_filled.columns[gross_index + 1:].tolist()\n",
    "df_processed = df_filled.drop(columns=cols_to_drop_after_gross)\n",
    "\n",
    "target = 'IMDB_Rating'\n",
    "columns_to_drop = ['Series_Title', 'Overview', 'Director', 'Star1', 'Star2', 'Star3', 'Star4', target]\n",
    "X = df_processed.drop(columns=columns_to_drop, errors='ignore')\n",
    "y = df_processed[target]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    ('cat', categorical_transformer, make_column_selector(dtype_include=object))\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "final_model = Pipeline(steps=[\n",
    "    ('feature_creator', FeatureCreator()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "cv_splitter = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(final_model, X, y, cv=cv_splitter, scoring='r2', n_jobs=-1)\n",
    "\n",
    "print(f\"Score R¬≤ (valida√ß√£o cruzada): {np.mean(scores):.4f}\")\n",
    "\n",
    "print(\"A treinar o modelo final com todos os dados...\")\n",
    "final_model.fit(X, y)\n",
    "print(\"Treino conclu√≠do.\")\n",
    "\n",
    "model_filename = '../models/melhor_modelo.pkl'\n",
    "joblib.dump(final_model, model_filename)\n",
    "\n",
    "print(f\"Modelo salvo com sucesso no ficheiro: {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filme: The Shawshank Redemption\n",
      "Previs√£o da Nota IMDB: 8.9847\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "model_filename = '../models/melhor_modelo.pkl'\n",
    "\n",
    "dados_para_previsao = {\n",
    "    'Series_Title': 'The Shawshank Redemption',\n",
    "    'Released_Year': '1994',\n",
    "    'Certificate': 'A',\n",
    "    'Runtime': '142 min',\n",
    "    'Genre': 'Drama',\n",
    "    'Overview': '''Two imprisoned men bond over a number of years,\n",
    "finding solace and eventual redemption through acts of common\n",
    "decency.''',\n",
    "    'Meta_score': 80.0,\n",
    "    'Director': 'Frank Darabont',\n",
    "    'Star1': 'Tim Robbins',\n",
    "    'Star2': 'Morgan Freeman',\n",
    "    'Star3': 'Bob Gunton',\n",
    "    'Star4': 'William Sadler',\n",
    "    'No_of_Votes': 2343110,\n",
    "    'Gross': '28,341,469'\n",
    "}\n",
    "\n",
    "\n",
    "try:\n",
    "    loaded_model = joblib.load(model_filename)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: O ficheiro do modelo '{model_filename}' n√£o foi encontrado. Por favor, execute primeiro o script de treino para salvar o modelo.\")\n",
    "    exit()\n",
    "\n",
    "input_df = pd.DataFrame([dados_para_previsao])\n",
    "input_df['Released_Year'] = pd.to_numeric(input_df['Released_Year'])\n",
    "input_df['Runtime'] = input_df['Runtime'].str.replace(' min', '').astype(int)\n",
    "input_df['Gross'] = input_df['Gross'].str.replace(',', '').astype(float)\n",
    "\n",
    "predicted_rating = loaded_model.predict(input_df)\n",
    "\n",
    "print(f\"Filme: {dados_para_previsao['Series_Title']}\")\n",
    "print(f\"Previs√£o da Nota IMDB: {predicted_rating[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e Salvamento\n",
    "Ap√≥s valida√ß√£o, treinamos o modelo em todos os dados dispon√≠veis e o salvamos com `joblib`.  \n",
    "Esse passo garante reprodutibilidade e facilita o reuso do modelo em produ√ß√£o ou em an√°lises futuras.\n",
    "\n",
    "\n",
    "Beleza, Artur üöÄ\n",
    "As tuas conclus√µes finais est√£o boas, mas d√° pra deixar mais claras, objetivas e com um tom mais **anal√≠tico/profissional**.\n",
    "Sugiro algo assim (mantendo a ess√™ncia do que j√° colocou):\n",
    "\n",
    "---\n",
    "\n",
    "### Conclus√µes Finais\n",
    "\n",
    "* O modelo previu a nota do filme **The Shawshank Redemption** como aproximadamente **8,97**, valor bastante pr√≥ximo da avalia√ß√£o real da obra.\n",
    "* As m√©tricas de desempenho, como **MSE** e **R¬≤**, mostraram limita√ß√µes relacionadas ao tamanho reduzido da amostra e √† alta variabilidade dos dados, o que imp√¥s um teto natural na performance do modelo.\n",
    "* A an√°lise explorat√≥ria revelou a presen√ßa de **outliers significativos**, sobretudo em vari√°veis como bilheteria (*Gross*) e notas, refletindo o comportamento comum do mercado cinematogr√°fico, no qual alguns filmes t√™m desempenhos muito acima ou abaixo da m√©dia.\n",
    "* Apesar dessas restri√ß√µes, o modelo conseguiu capturar rela√ß√µes relevantes entre vari√°veis explicativas e a nota do IMDB, sendo uma base s√≥lida para futuras melhorias com **mais dados, t√©cnicas de regulariza√ß√£o ou ajuste fino de hiperpar√¢metros**.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
