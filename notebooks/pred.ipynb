{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pra prever a nota do **IMDB** (`IMDB_Rating`) tratei o problema como uma tarefa de **regressão**, já q a variável alvo é continua (vai de 0 até 10).  \n",
    "\n",
    "As variáveis q usei foram:  \n",
    "- **Numéricas**: `Runtime` (convertido p/ minutos), `Meta_score`, `No_of_Votes`, `Gross` (ajustado p/ número).  \n",
    "- **Categóricas**: `Genre`, `Certificate`, `Director` e os atores principais (`Star1`–`Star4`).  \n",
    "  Nessas apliquei `OneHot` ou contagem de freq p/ transformar em número.  \n",
    "- **Transformações extras**:  \n",
    "  - Normalizei escalas numéricas ($MinMaxScaler$), pq atributos como $No\\_of\\_Votes$ e $Gross$ tem magnitudes mt diferentes.  \n",
    "  - No `Genre`, como pode ter + de um valor, fiz one-hot multirótulo (cada gênero vira 0/1 separado).\n",
    "\n",
    "O modelo q testei foi o **Random Forest Regressor**.  \n",
    "- **Prós**: robusto a outliers, pega relações não lineares, n precisa assumir distribuição das variáveis.  \n",
    "- **Contras**: interpretabilidade baixa e custo comp. maior q modelos lineares.  \n",
    "\n",
    "Como métrica, escolhi o **RMSE** ($\\sqrt{MSE}$) pq dá o erro médio direto na escala do IMDB.  \n",
    "Além disso tb usei o $R^2$ como complemento p/ ver a proporção da variância explicada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "path = '..\\\\data\\\\processed\\\\final_df.csv'\n",
    "\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "\n",
    "\n",
    "class FeatureCreator(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, top_n_genres=15):\n",
    "        self.top_n_genres = top_n_genres\n",
    "        self.top_genres_ = []\n",
    "        self.max_year_ = 0\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        genres = X['Genre'].str.split(', ').explode()\n",
    "        self.top_genres_ = genres.value_counts().nlargest(self.top_n_genres).index.tolist()\n",
    "        if 'Released_Year' in X.columns:\n",
    "            self.max_year_ = X['Released_Year'].max()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X_transformed = X.copy()\n",
    "        if 'Released_Year' in X_transformed.columns and self.max_year_ > 0:\n",
    "            X_transformed['Movie_Age'] = self.max_year_ - X_transformed['Released_Year']\n",
    "        for genre in self.top_genres_:\n",
    "            X_transformed[f'is_{genre}'] = X_transformed['Genre'].str.contains(genre, case=False, na=False).astype(int)\n",
    "        if 'Meta_score' in X_transformed.columns and 'No_of_Votes' in X_transformed.columns:\n",
    "            X_transformed['Metascore_x_Votes'] = X_transformed['Meta_score'] * X_transformed['No_of_Votes']\n",
    "        X_transformed = X_transformed.drop(columns=['Genre'], errors='ignore')\n",
    "        return X_transformed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Engenharia de Features com `FeatureCreator`\n",
    "Aqui criamos um transformador customizado para enriquecer os dados de filmes antes de treinar o modelo.  \n",
    "O objetivo é extrair variáveis mais informativas a partir das já existentes.\n",
    "\n",
    "- **Top Gêneros**: a coluna `Genre` pode conter múltiplos valores. Extraímos os `top_n` gêneros mais frequentes e criamos variáveis binárias (`is_Drama`, `is_Action`, etc.) indicando se o filme pertence a eles. Isso ajuda o modelo a capturar relações entre gênero e nota do IMDB.  \n",
    "- **Idade do Filme**: calculamos `Movie_Age` como a diferença entre o ano mais recente do dataset e o ano de lançamento. Filmes mais antigos tendem a acumular votos e avaliações diferentes dos mais novos.  \n",
    "- **Interação entre notas e popularidade**: criamos a variável `Metascore_x_Votes`, que combina a avaliação da crítica (`Meta_score`) com o número de votos do público (`No_of_Votes`). Essa interação pode ser um forte preditor da nota do IMDB, pois reflete a percepção crítica e a representatividade da amostra de votos.  \n",
    "- Ao final, removemos a coluna original `Genre`, já que sua informação foi decomposta em variáveis mais úteis.\n",
    "\n",
    "Esse tipo de **engenharia de features direcionada** geralmente aumenta a capacidade preditiva de modelos baseados em árvores, como `GradientBoostingRegressor`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_gross_with_revenue(df):\n",
    "    df_copy = df.copy()\n",
    "    gross_mean = df_copy['Gross'].mean()\n",
    "    revenue_mean = df_copy['Revenue'].mean()\n",
    "    factor = revenue_mean / gross_mean if pd.notna(gross_mean) and pd.notna(revenue_mean) and gross_mean > 0 else 1.0\n",
    "    df_copy['Gross'] = df_copy['Gross'].fillna(df_copy['Revenue'] / factor)\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Função de imputação de `Gross` com base em `Revenue`\n",
    "Muitos filmes não têm valor de bilheteria (`Gross`) registrado, mas têm receita total (`Revenue`).  \n",
    "A estratégia aqui é preencher os valores ausentes de `Gross` estimando-os proporcionalmente a `Revenue`.\n",
    "\n",
    "- Calculamos um **fator de ajuste** como a razão entre as médias de $Revenue$ e $Gross.  \n",
    "- Quando $Gross$ é nulo, substituímos por $\\frac{Revenue}{ fator}$.  \n",
    "- Essa técncia reduz perda de informação sem simplesmente descartar linhas ou usar média bruta, mantendo coerência com a escala financeira dos filmes.  \n",
    "\n",
    "Essa abordagem evita **vazamnto de dados**, pq é aplicada dentro de cada partição do treino/validaçao no pipeline, garantindo que estatísticas de imputação sejam aprendidas apenas a partir dos dados disponiveis no conjunto de treino.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score R² (validação cruzada): 0.5264\n",
      "A treinar o modelo final com todos os dados...\n",
      "Treino concluído.\n",
      "Modelo salvo com sucesso no ficheiro: ../models/melhor_modelo.pkl\n"
     ]
    }
   ],
   "source": [
    "df_filled = fill_gross_with_revenue(df)\n",
    "\n",
    "gross_index = df_filled.columns.get_loc('Gross')\n",
    "cols_to_drop_after_gross = df_filled.columns[gross_index + 1:].tolist()\n",
    "df_processed = df_filled.drop(columns=cols_to_drop_after_gross)\n",
    "\n",
    "target = 'IMDB_Rating'\n",
    "columns_to_drop = ['Series_Title', 'Overview', 'Director', 'Star1', 'Star2', 'Star3', 'Star4', target]\n",
    "X = df_processed.drop(columns=columns_to_drop, errors='ignore')\n",
    "y = df_processed[target]\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "    ('cat', categorical_transformer, make_column_selector(dtype_include=object))\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "final_model = Pipeline(steps=[\n",
    "    ('feature_creator', FeatureCreator()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "cv_splitter = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(final_model, X, y, cv=cv_splitter, scoring='r2', n_jobs=-1)\n",
    "\n",
    "print(f\"Score R² (validação cruzada): {np.mean(scores):.4f}\")\n",
    "\n",
    "print(\"A treinar o modelo final com todos os dados...\")\n",
    "final_model.fit(X, y)\n",
    "print(\"Treino concluído.\")\n",
    "\n",
    "model_filename = '../models/melhor_modelo.pkl'\n",
    "joblib.dump(final_model, model_filename)\n",
    "\n",
    "print(f\"Modelo salvo com sucesso no ficheiro: {model_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filme: The Shawshank Redemption\n",
      "Previsão da Nota IMDB: 8.9847\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "model_filename = '../models/melhor_modelo.pkl'\n",
    "\n",
    "dados_para_previsao = {\n",
    "    'Series_Title': 'The Shawshank Redemption',\n",
    "    'Released_Year': '1994',\n",
    "    'Certificate': 'A',\n",
    "    'Runtime': '142 min',\n",
    "    'Genre': 'Drama',\n",
    "    'Overview': '''Two imprisoned men bond over a number of years,\n",
    "finding solace and eventual redemption through acts of common\n",
    "decency.''',\n",
    "    'Meta_score': 80.0,\n",
    "    'Director': 'Frank Darabont',\n",
    "    'Star1': 'Tim Robbins',\n",
    "    'Star2': 'Morgan Freeman',\n",
    "    'Star3': 'Bob Gunton',\n",
    "    'Star4': 'William Sadler',\n",
    "    'No_of_Votes': 2343110,\n",
    "    'Gross': '28,341,469'\n",
    "}\n",
    "\n",
    "\n",
    "try:\n",
    "    loaded_model = joblib.load(model_filename)\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: O ficheiro do modelo '{model_filename}' não foi encontrado. Por favor, execute primeiro o script de treino para salvar o modelo.\")\n",
    "    exit()\n",
    "\n",
    "input_df = pd.DataFrame([dados_para_previsao])\n",
    "input_df['Released_Year'] = pd.to_numeric(input_df['Released_Year'])\n",
    "input_df['Runtime'] = input_df['Runtime'].str.replace(' min', '').astype(int)\n",
    "input_df['Gross'] = input_df['Gross'].str.replace(',', '').astype(float)\n",
    "\n",
    "predicted_rating = loaded_model.predict(input_df)\n",
    "\n",
    "print(f\"Filme: {dados_para_previsao['Series_Title']}\")\n",
    "print(f\"Previsão da Nota IMDB: {predicted_rating[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento e Salvamento\n",
    "Após validação, treinamos o modelo em todos os dados disponíveis e o salvamos com `joblib`.  \n",
    "Esse passo garante reprodutibilidade e facilita o reuso do modelo em produção ou em análises futuras.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
